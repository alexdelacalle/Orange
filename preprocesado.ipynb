{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Librerías"
      ],
      "metadata": {
        "id": "QsJsSI29wi9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "U_GOr1v7qDU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura de datos"
      ],
      "metadata": {
        "id": "pkEaygz1womk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = pd.read_csv('TRAIN.csv')\n",
        "train = pd.DataFrame(train_file)"
      ],
      "metadata": {
        "id": "FStnJg8Iv6bn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de hacer nada, eliminamos los id, que no aportan ninguna información, y las fechas de modificación de las filas."
      ],
      "metadata": {
        "id": "Gb54hdleJyGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns=['customer_id', 'EOP_DAY'])"
      ],
      "metadata": {
        "id": "knp3iKx93b5R"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesado"
      ],
      "metadata": {
        "id": "lQUkcofgwyZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Borrado de columnas con un solo valor"
      ],
      "metadata": {
        "id": "MyxMv_pH3klL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a eliminar las columnas que no tienen más valores que 1, es decir, solo aportan coste de computación y son prescindibles."
      ],
      "metadata": {
        "id": "2e4uZVS23sEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EliminarColumnasConstantes(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.columnas_a_mantener = [col for col in X.columns if X[col].nunique() > 1]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.columnas_a_mantener]"
      ],
      "metadata": {
        "id": "81mQwJLExTiJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratamiento de valores nulos"
      ],
      "metadata": {
        "id": "zDMgYwq740LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al analizar el dataset, se puede ver a simple vista que hay muchos valores 99999 y -9999 que parecen estar metidos a mano o para no poner un NaN. Como de momento no les podemos sacar ningún significado más que un número sustituto, los transformaremos en NaN para su posterior tratamiento."
      ],
      "metadata": {
        "id": "Qn2mjdNT46od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReemplazarValoresInvalidos(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, valores_a_reemplazar=None):\n",
        "        self.valores_a_reemplazar = valores_a_reemplazar or [99999, -9999]\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.replace(self.valores_a_reemplazar, np.nan)"
      ],
      "metadata": {
        "id": "99dmYjZuxiAz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos todos nuestros valores nulos, tenemos que mirar un factor muy importante para elegir nuestra estrategia. En primer lugar, tenemos que ver qué porcentaje de los datos es nulo, es decir, si tenemos una columna con 80% de datos nulos, no tiene rescate ninguno.\n",
        "\n",
        "Para ello primero eliminamos columnas con alto porcentaje de datos nulos."
      ],
      "metadata": {
        "id": "5uNubL4o5rvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EliminarColumnasConMuchosNaN(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, umbral=0.3):\n",
        "        self.umbral = umbral\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columnas_a_mantener = X.columns[X.isnull().mean() <= self.umbral]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.columnas_a_mantener]"
      ],
      "metadata": {
        "id": "bBpE83yO5gvg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora tenemos las columnas que se pueden \"restaurar\" o más bien falsear para no tener que borrar datos y que no contamine de forma significativa el modelo. Para ello, seguimos estos 2 enfoques:\n",
        "\n",
        "\n",
        "*   **Caso categórico**: Reemplazamos el valor por la categoría más repetida, es decir, la **moda**.\n",
        "*   **Caso numérico**: Reemplazamos el valor por la **mediana**.\n",
        "\n"
      ],
      "metadata": {
        "id": "FabSI07t6syR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocesamiento numérico ---\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])\n",
        "\n",
        "# --- Preprocesamiento categórico ---\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])"
      ],
      "metadata": {
        "id": "wO4Vc0L671cB"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtrado de datos relevantes"
      ],
      "metadata": {
        "id": "rHQFgZSI8fbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, vamos a quitar las columnas que estén intrínsecamente relacionadas con otras columnas, es decir, que no estén aportando nueva información."
      ],
      "metadata": {
        "id": "0Z7QiD048mXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 5: Eliminar columnas altamente correlacionadas\n",
        "class EliminarColumnasCorrelacionadas(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, umbral=0.9):\n",
        "        self.umbral = umbral\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        corr_matrix = X.corr().abs()\n",
        "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "        self.columnas_a_eliminar = [column for column in upper.columns if any(upper[column] > self.umbral)]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.drop(columns=self.columnas_a_eliminar)"
      ],
      "metadata": {
        "id": "5YXs21-g88qd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline de preprocesado"
      ],
      "metadata": {
        "id": "Vy-VLtag9LkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear un pipeline que nos permita hacer todo el preprocesado de golpe sin tener que ir paso por paso."
      ],
      "metadata": {
        "id": "N0ZcOoWh9Rrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PipelinePreprocesamiento(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.step1 = EliminarColumnasConstantes()\n",
        "        self.step2 = ReemplazarValoresInvalidos()\n",
        "        self.step3 = EliminarColumnasConMuchosNaN(umbral=0.3)\n",
        "        self.step5 = EliminarColumnasCorrelacionadas(umbral=0.9)\n",
        "        self.preprocesador_columnas = None\n",
        "        self.column_names_ = None  # Para guardar los nombres finales\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Paso 1 a 3\n",
        "        X_clean = self.step1.fit_transform(X)\n",
        "        X_clean = self.step2.fit_transform(X_clean)\n",
        "        X_clean = self.step3.fit_transform(X_clean)\n",
        "\n",
        "        # Detección de tipos\n",
        "        self.columnas_num = X_clean.select_dtypes(include='number').columns.tolist()\n",
        "        self.columnas_cat = X_clean.select_dtypes(exclude='number').columns.tolist()\n",
        "\n",
        "        # ColumnTransformer\n",
        "        self.preprocesador_columnas = ColumnTransformer([\n",
        "            ('num', numerical_pipeline, self.columnas_num),\n",
        "            ('cat', categorical_pipeline, self.columnas_cat)\n",
        "        ])\n",
        "\n",
        "        # Ajustar column transformer\n",
        "        self.preprocesador_columnas.fit(X_clean)\n",
        "\n",
        "        # Obtener nombres de columnas finales\n",
        "        num_features = self.columnas_num\n",
        "        cat_features = self.preprocesador_columnas.named_transformers_['cat']\\\n",
        "                          .named_steps['encoder']\\\n",
        "                          .get_feature_names_out(self.columnas_cat).tolist()\n",
        "\n",
        "        self.column_names_ = num_features + cat_features\n",
        "\n",
        "        # Para correlación (paso 5)\n",
        "        X_encoded = self.preprocesador_columnas.transform(X_clean)\n",
        "        X_encoded_df = pd.DataFrame(X_encoded, columns=self.column_names_)\n",
        "        self.step5.fit(X_encoded_df)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_clean = self.step1.transform(X)\n",
        "        X_clean = self.step2.transform(X_clean)\n",
        "        X_clean = self.step3.transform(X_clean)\n",
        "\n",
        "        X_encoded = self.preprocesador_columnas.transform(X_clean)\n",
        "        X_encoded_df = pd.DataFrame(X_encoded, columns=self.column_names_)\n",
        "\n",
        "        X_final = self.step5.transform(X_encoded_df)\n",
        "\n",
        "        # Retorna DataFrame con nombres limpios\n",
        "        return pd.DataFrame(X_final, columns=X_encoded_df.columns.drop(self.step5.columnas_a_eliminar))"
      ],
      "metadata": {
        "id": "OnhaYM0C9H8W"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesado del dataset"
      ],
      "metadata": {
        "id": "C8ddei2jKGXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocesador = PipelinePreprocesamiento()\n",
        "X_limpio = preprocesador.fit_transform(train)"
      ],
      "metadata": {
        "id": "lK6UD2C--OkH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportación de datos"
      ],
      "metadata": {
        "id": "FilV4sxVANy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez tenemos los datos limpios, podemos pasar a la exportación del dataset limpio."
      ],
      "metadata": {
        "id": "48Hb9dA6AVI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_limpio.to_csv('dataset_jazztel_limpio.csv', index=False)"
      ],
      "metadata": {
        "id": "uAjkytmXAij-"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}